---
phase: 04-gymnasium-environment-wrapper
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/ai/ai-config.ts
  - src/ai/raycaster.ts
  - src/ai/observations.ts
  - src/ai/reward.ts
  - tests/ai/raycaster.test.ts
  - tests/ai/observations.test.ts
  - tests/ai/reward.test.ts
autonomous: true
requirements: [AI-02, AI-03, AI-04, AI-05, AI-06, AI-12, AI-13]

must_haves:
  truths:
    - "9 rays cast across 180-degree forward arc return normalized distances to boundary walls"
    - "14-value observation vector contains all required components normalized to [-1,1] or [0,1]"
    - "Dense per-tick reward sums checkpoint progress (primary) and speed bonus"
    - "Four-tier penalties (stillness, wall, off-track, backward) are computed separately"
    - "Penalties are always smaller in magnitude than typical progress rewards"
    - "Reward weights are loaded from a config object (no hardcoding)"
    - "Each reward component is returned individually for per-component logging"
  artifacts:
    - path: "src/ai/ai-config.ts"
      provides: "RewardConfig type, default weights, episode config"
      exports: ["RewardConfig", "EpisodeConfig", "AiConfig", "DEFAULT_AI_CONFIG"]
    - path: "src/ai/raycaster.ts"
      provides: "9-ray cast against track boundary polylines"
      exports: ["castRays", "raySegmentIntersection"]
    - path: "src/ai/observations.ts"
      provides: "14-value normalized observation vector builder"
      exports: ["buildObservation"]
    - path: "src/ai/reward.ts"
      provides: "Reward computation with per-component breakdown"
      exports: ["computeReward", "RewardBreakdown"]
    - path: "tests/ai/raycaster.test.ts"
      provides: "Ray casting unit tests"
    - path: "tests/ai/observations.test.ts"
      provides: "Observation vector unit tests"
    - path: "tests/ai/reward.test.ts"
      provides: "Reward computation unit tests"
  key_links:
    - from: "src/ai/raycaster.ts"
      to: "src/engine/types.ts"
      via: "imports Vec2, TrackState for ray casting against innerBoundary/outerBoundary"
      pattern: "import.*TrackState.*from.*engine/types"
    - from: "src/ai/observations.ts"
      to: "src/ai/raycaster.ts"
      via: "uses castRays() output as first 9 values of observation vector"
      pattern: "import.*castRays.*from.*raycaster"
    - from: "src/ai/reward.ts"
      to: "src/ai/ai-config.ts"
      via: "reads RewardConfig weights for component computation"
      pattern: "import.*RewardConfig.*from.*ai-config"
---

<objective>
Build the three core AI computation modules: ray casting, observation vector, and reward function. These are pure TypeScript functions that run engine-side with well-defined I/O -- ideal for TDD.

Purpose: These modules provide the AI agent's sensory input (what it sees) and feedback signal (what it learns from). They must be correct, normalized, and testable independently from the bridge layer.

Output: Four TypeScript source files in `src/ai/` with comprehensive test coverage in `tests/ai/`. All computation happens engine-side (zero Python, zero network).
</objective>

<execution_context>
@~/.claude/commands/gsd/workflows/execute-plan.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md

<interfaces>
<!-- Key types and contracts the executor needs from the engine. -->

From src/engine/types.ts:
```typescript
export interface Vec2 { readonly x: number; readonly y: number; }
export const enum Surface { Road = 0, Runoff = 1, Shoulder = 2 }
export interface Input { steer: number; throttle: number; brake: number; }
export interface SmoothedInput { steer: number; throttle: number; brake: number; steerAngle: number; }
export interface CarState {
  position: Vec2; velocity: Vec2; heading: number; yawRate: number;
  speed: number; prevInput: SmoothedInput; surface: Surface;
  accelLongitudinal: number; slipAngle: number;
}
export interface Checkpoint { left: Vec2; right: Vec2; center: Vec2; direction: Vec2; arcLength: number; }
export interface TrackState {
  controlPoints: readonly TrackControlPoint[];
  innerBoundary: readonly Vec2[]; outerBoundary: readonly Vec2[];
  innerRoadEdge: readonly Vec2[]; outerRoadEdge: readonly Vec2[];
  checkpoints: readonly Checkpoint[];
  arcLengthTable: ArcLengthTable;
  totalLength: number; startPosition: Vec2; startHeading: number;
}
export interface TimingState {
  currentLapTicks: number; bestLapTicks: number; totalRaceTicks: number;
  currentLap: number; lastCheckpointIndex: number; lapComplete: boolean;
  lapTimes: readonly number[];
}
export interface WorldState { tick: number; car: CarState; track: TrackState; timing: TimingState; }
export interface CollisionResult { collided: boolean; penetration: number; normal: Vec2; contactPoint: Vec2; }
```

From src/engine/constants.ts:
```typescript
export const CAR = { mass: 800, maxSpeed: 160, width: 2.0, /* ... */ } as const;
```

From src/engine/vec2.ts:
```typescript
export function vec2(x: number, y: number): Vec2;
export function sub(a: Vec2, b: Vec2): Vec2;
export function dot(a: Vec2, b: Vec2): number;
export function length(v: Vec2): number;
export function normalize(v: Vec2): Vec2;
export function fromAngle(angle: number): Vec2;
// ... plus add, scale, cross, rotate, distance, etc.
```

From src/engine/track.ts:
```typescript
export function distanceToTrackCenter(position: Vec2, track: TrackState): { distance: number; arcLength: number };
export function getSurface(position: Vec2, track: TrackState): Surface;
```

From src/engine/collision.ts:
```typescript
export function pointToSegmentDistance(point: Vec2, segA: Vec2, segB: Vec2): { distance: number; nearest: Vec2; t: number };
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create AI config types and ray caster with TDD</name>
  <files>
    src/ai/ai-config.ts
    src/ai/raycaster.ts
    tests/ai/raycaster.test.ts
  </files>
  <action>
**Step 1: Create `src/ai/ai-config.ts`** -- Type definitions and default config.

```typescript
export interface RewardConfig {
  progress: number;      // Weight for checkpoint arc-length delta (primary signal)
  speedBonus: number;    // Weight for normalized speed bonus
  wallPenalty: number;    // Negative weight for wall collision
  offtrackPenalty: number; // Negative weight for off-track (runoff/shoulder)
  backwardPenalty: number; // Negative weight for backward driving
  stillnessPenalty: number; // Negative weight for being too slow
}

export interface EpisodeConfig {
  maxSteps: number;              // Max ticks per episode (3000 = 50s at 60Hz)
  stillnessTimeoutTicks: number; // Ticks below speed threshold before termination
  stillnessSpeedThreshold: number; // Speed below this counts as "still"
}

export interface AiConfig {
  weights: RewardConfig;
  episode: EpisodeConfig;
}

export const DEFAULT_AI_CONFIG: AiConfig = {
  weights: {
    progress: 1.0,
    speedBonus: 0.1,
    wallPenalty: -0.05,
    offtrackPenalty: -0.02,
    backwardPenalty: -0.1,
    stillnessPenalty: -0.1,
  },
  episode: {
    maxSteps: 3000,
    stillnessTimeoutTicks: 180,
    stillnessSpeedThreshold: 2.0,
  },
};
```

**Step 2: RED -- Write failing tests for `raycaster.ts`** in `tests/ai/raycaster.test.ts`.

Test cases for `raySegmentIntersection(origin, direction, segA, segB)`:
- Ray hits a horizontal segment perpendicular -> returns correct distance
- Ray hits a vertical segment -> returns correct distance
- Ray parallel to segment -> returns null
- Ray pointing away from segment -> returns null
- Ray misses segment (passes to the side) -> returns null
- Segment behind ray origin -> returns null

Test cases for `castRays(carPosition, carHeading, track, numRays, fovRadians, maxDist)`:
- Create a simple rectangular "track" with 4 boundary segments forming a box (inner + outer boundaries as Vec2[])
- Car at center, heading right (0 radians): verify 9 rays return distances to the box walls
- All ray values are normalized to [0, 1] (divided by maxDist)
- Car near a wall: the closest ray should have a small value, far rays should be larger
- With maxDist=200 and no wall hit: ray returns 1.0

Use `buildTrack` from `src/engine/track.ts` with a simple track to create realistic test boundaries, OR construct synthetic boundary polylines directly for unit-level isolation. Prefer synthetic for unit tests.

**Step 3: GREEN -- Implement `src/ai/raycaster.ts`.**

```typescript
export function raySegmentIntersection(
  origin: Vec2, direction: Vec2, segA: Vec2, segB: Vec2
): number | null
```
Uses the parametric line-segment intersection formula. Same math as `checkGateCrossing` in checkpoint.ts. Ray: `P = origin + t * direction` (t >= 0). Segment: `Q = segA + u * (segB - segA)` (u in [0, 1]). Return t (distance) if hit, null if miss.

```typescript
export function castRays(
  carPosition: Vec2, carHeading: number,
  innerBoundary: readonly Vec2[], outerBoundary: readonly Vec2[],
  numRays?: number, fovRadians?: number, maxDist?: number
): number[]
```
Defaults: numRays=9, fovRadians=Math.PI (180 degrees), maxDist=200. Cast rays from car position at angles `heading - fov/2` to `heading + fov/2` at equal intervals. For each ray, test against ALL segments of both `innerBoundary` and `outerBoundary`. Return `min(hitDist, maxDist) / maxDist` -- normalized to [0, 1].

**Important:** The function takes `innerBoundary` and `outerBoundary` as separate arrays (not the full TrackState) to keep the API clean and testable. The caller (headless-env or observations) extracts boundaries from TrackState.

**Step 4: REFACTOR** if needed. Ensure no unnecessary allocations in the hot path (castRays is called every tick).

Run `pnpm test -- tests/ai/raycaster.test.ts` -- all tests must pass.
  </action>
  <verify>
    <automated>cd C:/Users/brigg/ai-learning-journey/projects/top-down-racer-02 && pnpm test -- tests/ai/raycaster.test.ts</automated>
  </verify>
  <done>
    - ai-config.ts exports RewardConfig, EpisodeConfig, AiConfig types and DEFAULT_AI_CONFIG constant
    - raySegmentIntersection returns distance on hit, null on miss
    - castRays returns 9 normalized [0,1] values for a car position/heading against boundaries
    - All raycaster tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Create observation vector builder and reward function with TDD</name>
  <files>
    src/ai/observations.ts
    src/ai/reward.ts
    tests/ai/observations.test.ts
    tests/ai/reward.test.ts
  </files>
  <action>
**Step 1: RED -- Write failing tests for `observations.ts`** in `tests/ai/observations.test.ts`.

Test cases for `buildObservation(world, rays)`:
- Returns array of exactly 14 numbers
- First 9 values are the ray values passed in (unchanged)
- Value 10: speed normalized to [0, 1] via `car.speed / CAR.maxSpeed`
- Value 11: yaw rate normalized to [-1, 1] via `clamp(car.yawRate / 5.0, -1, 1)`
- Value 12: steering input [-1, 1] from `car.prevInput.steer` (already in range)
- Value 13: lap progress [0, 1] from checkpoint arc-length / track total length
- Value 14: centerline distance normalized to [0, 1] via `min(1, distance / maxHalfWidth)` where maxHalfWidth = 50
- All values are within [-1, 1] range (the union of all component ranges)
- Edge cases: speed at max, yaw rate beyond clamp range, car at checkpoint 0

Use mock WorldState objects (no need to run the engine). Create minimal mock with required fields.

**Step 2: GREEN -- Implement `src/ai/observations.ts`.**

```typescript
export function buildObservation(world: WorldState, rays: number[]): number[]
```

Builds the 14-value vector per AI-03:
1. rays[0..8] -- 9 ray distances, already normalized to [0, 1]
2. `car.speed / CAR.maxSpeed` -- normalized speed [0, 1]
3. `clamp(car.yawRate / 5.0, -1, 1)` -- angular velocity [-1, 1]
4. `car.prevInput.steer` -- current steering [-1, 1]
5. `checkpointArcLength / track.totalLength` -- lap progress [0, 1]
6. `min(1, centerlineDist / 50)` -- centerline distance [0, 1]

Import `distanceToTrackCenter` from `../engine/track` for the centerline distance calculation. Import `CAR` from `../engine/constants` for maxSpeed.

For lap progress: use `track.checkpoints[timing.lastCheckpointIndex].arcLength / track.totalLength`. Handle edge case where `lastCheckpointIndex === 0` (could be start or wrap-around).

**Step 3: RED -- Write failing tests for `reward.ts`** in `tests/ai/reward.test.ts`.

Test cases for `computeReward(prevWorld, currWorld, config)`:
- Forward progress between checkpoints produces positive reward
- Progress reward is based on arc-length delta between checkpoint positions
- Speed bonus is proportional to `car.speed / CAR.maxSpeed * config.speedBonus`
- Wall collision (detect via `detectWallCollision` or pass collision state) applies `config.wallPenalty`
- Off-track surface (Surface.Runoff or Surface.Shoulder) applies `config.offtrackPenalty`
- Backward driving (negative progress delta) applies `config.backwardPenalty`
- Stillness (speed below threshold) applies `config.stillnessPenalty`
- Total reward is sum of all components
- Each component is returned individually in `RewardBreakdown` (AI-13)
- With default config, penalty magnitudes are smaller than typical progress reward (AI-06)
- Progress wrapping at lap boundary works correctly (modular arithmetic)
- Configuring different weights produces different reward values (AI-12)

```typescript
export interface RewardBreakdown {
  progress: number;
  speed: number;
  wall: number;
  offTrack: number;
  backward: number;
  stillness: number;
  total: number;
}
```

**Step 4: GREEN -- Implement `src/ai/reward.ts`.**

```typescript
export function computeReward(
  prevWorld: WorldState, currWorld: WorldState, config: RewardConfig
): RewardBreakdown
```

Progress calculation: Get arc-length of current and previous checkpoint positions. Delta = `(currArc - prevArc + totalLength) % totalLength`. If delta > totalLength/2, treat as backward (impossible forward distance in one tick). Normalize by totalLength so progress per tick is a small fraction.

Speed bonus: `(currWorld.car.speed / CAR.maxSpeed) * config.speedBonus`.

Wall penalty: `config.wallPenalty` if current car is colliding with a wall. Detect by checking if the car position is within collision radius of any boundary segment. Use `detectWallCollision` from `../engine/collision` or check `car.surface` -- actually, wall collision is NOT stored in CarState directly. Instead, check if the car's distance to nearest boundary is less than the collision radius (CAR.width / 2). Alternatively, since the reward function receives both prevWorld and currWorld, detect wall contact by checking if the car position changed in a way consistent with collision resolution (speed dropped significantly + position shifted). **Simpler approach:** Add a `wallContact` boolean to the info returned by HeadlessEnv (computed in headless-env.ts during stepWorld), and pass it into computeReward. For now, detect by running `detectWallCollision` inside reward.ts -- it's cheap enough.

Off-track: Check `currWorld.car.surface !== Surface.Road`. Apply offtrackPenalty if on Runoff or Shoulder.

Backward: Negative progress delta (after modular correction).

Stillness: `currWorld.car.speed < config episode threshold` -- but wait, reward.ts receives RewardConfig, not EpisodeConfig. Either pass the threshold separately or include it in the reward call. **Decision:** Add `stillnessSpeedThreshold` as a parameter to computeReward, or pass the full AiConfig. Pass `AiConfig` to keep it clean.

Actually, looking more carefully: computeReward should take `AiConfig` (not just `RewardConfig`) so it has access to `episode.stillnessSpeedThreshold`. Or take `RewardConfig & { stillnessSpeedThreshold: number }`. Use `AiConfig` for simplicity.

**Step 5: REFACTOR** both modules. Ensure clean imports, no circular dependencies.

Run `pnpm test -- tests/ai/observations.test.ts tests/ai/reward.test.ts` -- all tests must pass.

Also run the full test suite to verify no regressions: `pnpm test`.
  </action>
  <verify>
    <automated>cd C:/Users/brigg/ai-learning-journey/projects/top-down-racer-02 && pnpm test -- tests/ai/observations.test.ts tests/ai/reward.test.ts</automated>
  </verify>
  <done>
    - buildObservation returns exactly 14 normalized values: 9 rays + speed + yawRate + steering + lapProgress + centerlineDist
    - computeReward returns RewardBreakdown with all 6 components + total
    - Progress wrapping at lap boundary produces correct positive delta
    - Default config satisfies AI-06: penalties smaller than progress rewards
    - Configurable weights change reward output (AI-12)
    - All observation and reward tests pass
    - Full test suite passes (no regressions)
  </done>
</task>

</tasks>

<verification>
1. `pnpm test` -- all tests pass including new ai/ tests and existing engine/ tests
2. `pnpm exec tsc --noEmit` -- no TypeScript errors
3. All 4 new source files exist in src/ai/ with correct exports
4. All 3 new test files exist in tests/ai/ with passing assertions
5. Ray values are always in [0, 1], observation values in [-1, 1]
6. Reward breakdown total equals sum of components
</verification>

<success_criteria>
- 9-ray cast returns normalized distances against track boundaries (AI-02)
- 14-value observation vector contains all required components (AI-03)
- Dense per-tick reward with checkpoint progress primary signal (AI-04)
- Four-tier penalties computed separately (AI-05)
- Default penalties smaller than progress rewards (AI-06)
- Reward weights configurable via AiConfig type (AI-12)
- Per-component reward breakdown returned for logging (AI-13)
</success_criteria>

<output>
After completion, create `.planning/phases/04-gymnasium-environment-wrapper/04-01-SUMMARY.md`
</output>
