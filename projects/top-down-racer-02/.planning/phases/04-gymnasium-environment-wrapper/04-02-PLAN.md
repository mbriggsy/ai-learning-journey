---
phase: 04-gymnasium-environment-wrapper
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - src/ai/headless-env.ts
  - src/ai/bridge-server.ts
  - src/ai/run-bridge.ts
  - python/ai-config.json
  - tests/ai/headless-env.test.ts
autonomous: true
requirements: [AI-01, AI-07]

must_haves:
  truths:
    - "HeadlessEnv wraps createWorld/stepWorld and produces observations, rewards, and termination signals per step"
    - "WebSocket bridge server accepts step/reset/close commands and returns JSON responses"
    - "Bridge server starts on a configurable port and logs 'ready' when listening"
    - "Default reward weights are stored in a JSON config file"
    - "Episode terminates on max steps (truncated) or stillness timeout (terminated)"
  artifacts:
    - path: "src/ai/headless-env.ts"
      provides: "Headless environment controller wrapping engine + AI modules"
      exports: ["HeadlessEnv", "StepResult", "ResetResult"]
    - path: "src/ai/bridge-server.ts"
      provides: "WebSocket RPC server for Python bridge"
      exports: ["startBridgeServer"]
    - path: "src/ai/run-bridge.ts"
      provides: "CLI entry point for bridge server"
    - path: "python/ai-config.json"
      provides: "Default reward weights and episode config"
    - path: "tests/ai/headless-env.test.ts"
      provides: "Headless env unit tests"
  key_links:
    - from: "src/ai/headless-env.ts"
      to: "src/engine/world.ts"
      via: "imports createWorld, stepWorld for episode management"
      pattern: "import.*createWorld.*stepWorld.*from.*engine/world"
    - from: "src/ai/headless-env.ts"
      to: "src/ai/raycaster.ts"
      via: "imports castRays for observation building"
      pattern: "import.*castRays.*from.*raycaster"
    - from: "src/ai/headless-env.ts"
      to: "src/ai/reward.ts"
      via: "imports computeReward for reward computation"
      pattern: "import.*computeReward.*from.*reward"
    - from: "src/ai/headless-env.ts"
      to: "src/engine/collision.ts"
      via: "imports detectWallCollision for wall contact detection"
      pattern: "import.*detectWallCollision.*from.*engine/collision"
    - from: "src/ai/headless-env.ts"
      to: "src/engine/track.ts"
      via: "imports distanceToTrackCenter for observation/reward shared computation"
      pattern: "import.*distanceToTrackCenter.*from.*engine/track"
    - from: "src/ai/bridge-server.ts"
      to: "src/ai/headless-env.ts"
      via: "creates HeadlessEnv instance and delegates step/reset"
      pattern: "import.*HeadlessEnv.*from.*headless-env"
    - from: "src/ai/run-bridge.ts"
      to: "src/ai/bridge-server.ts"
      via: "imports and calls startBridgeServer"
      pattern: "import.*startBridgeServer.*from.*bridge-server"
---

## Enhancement Summary

**Deepened on:** 2026-03-01
**Sections enhanced:** 2 tasks + interfaces + verification
**Research agents used:** 11 (TypeScript reviewer, architecture strategist, performance oracle, security sentinel, code simplicity reviewer, pattern recognition specialist, spec flow analyzer, WebSocket best practices researcher, RL environment design researcher, wall contact detection explorer, engine API explorer)
**External sources:** ws npm docs, tsx docs, Vitest docs, Gymnasium official docs, Nature 2025 reward design paper, F1Tenth RL studies, Marc Brooker TCP_NODELAY analysis, Node.js memory management docs

### Critical Issues Found and Resolved
1. **Interface signatures stale** -- Plan 02's `<interfaces>` block was written before Plan 01 was enhanced. All Plan 01 function signatures were wrong (`computeReward` missing `wallContact` param, `buildObservation` missing `trackProgress` param, `castRays` has removed optional params, `stillnessSpeedThreshold` in wrong config object). Fixed below.
2. **Wall contact undetectable** -- `stepWorld` resolves collisions internally; calling `detectWallCollision` on the resolved position returns `collided: false`. HeadlessEnv must detect wall contact independently using `detectWallCollision` with a padded radius on the post-step position.
3. **`python/ai-config.json` used rejected reward weights** -- Plan 01 spent significant research effort rebalancing weights (`speedBonus: 0.0`, `wallPenalty: -0.002`). Plan 02's JSON file had the old values (`speedBonus: 0.1`, `wallPenalty: -0.05`) that Plan 01 explicitly rejected. Fixed to match Plan 01.
4. **`offtrackPenalty` casing mismatch** -- JSON used `offtrackPenalty` (lowercase t) but TypeScript interface uses `offTrackPenalty` (camelCase). Would cause the off-track penalty to silently never fire. Fixed.
5. **ESM main-module detection is fragile** -- String-matching hack `process.argv[1]?.includes('bridge-server')` could match unrelated files. Replaced with a separate 3-line entry file `src/ai/run-bridge.ts`.
6. **Missing `distanceToTrackCenter` caching** -- Without caching, this expensive function (~500 spline evaluations) would be called 3x per tick instead of 1x. Added `prevTrackProgress` cache field to HeadlessEnv.
7. **`buildTrack` requires `checkpointCount`** -- Plan 02 showed it as optional, but it is required in the actual engine API. Added `CHECKPOINT_COUNT` constant.

### Key Improvements
1. `distanceToTrackCenter` computed once per tick, result shared with `buildObservation` and `computeReward` (3x -> 1x calls)
2. WebSocket server binds to `127.0.0.1` (localhost only), disables compression, enables TCP_NODELAY
3. Action validation checks `Number.isFinite()` before clamping (prevents NaN poisoning the physics engine)
4. Observation bounds assertion catches engine bugs early with clear error messages
5. Graceful shutdown handler for SIGINT/SIGTERM on bridge server
6. `buildTrack` checkpoint count set via constant (not renderer import)

### New Considerations Discovered
- Add `--max-semi-space-size=16` to the bridge npm script for better GC during long training runs (Phase 5)
- Consider switching from `ws` to shared-memory bridge if WebSocket latency (estimated ~100us) becomes a bottleneck (Phase 5)
- Consider adding `lapComplete` and `lapTime` to info dict for training metrics (Phase 5)
- Pre-compute `controlPoints.map(cp => cp.position)` on TrackState to avoid per-tick allocation in `distanceToTrackCenter` (Phase 5)

---

<objective>
Build the headless environment controller and WebSocket bridge server. HeadlessEnv wraps the engine's createWorld/stepWorld with AI-specific logic (ray casting, reward, termination). The bridge server exposes HeadlessEnv over WebSocket for Python to consume.

Purpose: This is the "adapter" layer that turns the game engine into an RL environment. The Python side (Plan 03) connects to this server.

Output: Three TypeScript source files in `src/ai/`, one JSON config file in `python/`, and unit tests for the headless env.
</objective>

<execution_context>
@~/.claude/commands/gsd/workflows/execute-plan.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-gymnasium-environment-wrapper/04-01-SUMMARY.md

<interfaces>
<!-- CORRECTED: All signatures verified against Plan 01's final (post-deepening) outputs, 2026-03-01 -->

From src/ai/ai-config.ts:
```typescript
export const RAY = { numRays: 9, fovRadians: Math.PI, maxDist: 200 } as const;
export const OBS = { maxYawRate: 5.0, maxCenterlineDist: 80, size: 14 } as const;

export interface RewardConfig {
  progress: number; speedBonus: number; wallPenalty: number;
  offTrackPenalty: number; backwardPenalty: number; stillnessPenalty: number;
  stillnessSpeedThreshold: number;  // NOTE: In RewardConfig, NOT EpisodeConfig
}
export interface EpisodeConfig {
  maxSteps: number; stillnessTimeoutTicks: number;
  // NOTE: stillnessSpeedThreshold was moved to RewardConfig per Plan 01
}
export interface AiConfig { weights: RewardConfig; episode: EpisodeConfig; }
export const DEFAULT_AI_CONFIG: AiConfig;
```

From src/ai/raycaster.ts:
```typescript
// NOTE: No optional params. Reads from RAY constant internally.
export function castRays(
  carPosition: Vec2, carHeading: number,
  innerBoundary: readonly Vec2[], outerBoundary: readonly Vec2[],
): number[];
```

From src/ai/observations.ts:
```typescript
export const OBSERVATION_SIZE = 14;
// NOTE: Third param `trackProgress` is REQUIRED (pre-computed by caller).
export function buildObservation(
  world: WorldState, rays: number[],
  trackProgress: { distance: number; arcLength: number },
): number[];
```

From src/ai/reward.ts:
```typescript
export interface RewardBreakdown {
  progress: number; speed: number; wall: number;
  offTrack: number; backward: number; stillness: number; total: number;
}
// NOTE: Takes wallContact boolean + RewardConfig (not AiConfig) + optional precomputed arc-lengths.
export function computeReward(
  prevWorld: WorldState, currWorld: WorldState,
  wallContact: boolean, config: RewardConfig,
  precomputed?: { prevArcLength: number; currArcLength: number },
): RewardBreakdown;
```

<!-- From engine (stable, unchanged) -->

From src/engine/world.ts:
```typescript
export function createWorld(track: TrackState): WorldState;
export function stepWorld(state: WorldState, input: Input): WorldState;
```

From src/engine/track.ts:
```typescript
// NOTE: checkpointCount is REQUIRED (not optional).
export function buildTrack(controlPoints: TrackControlPoint[], checkpointCount: number): TrackState;
export function distanceToTrackCenter(position: Vec2, track: TrackState): { distance: number; arcLength: number };
```

From src/engine/collision.ts:
```typescript
export function detectWallCollision(position: Vec2, radius: number, track: TrackState): CollisionResult;
```

From src/engine/constants.ts:
```typescript
export const CAR = { mass: 800, maxSpeed: 160, width: 2.0, /* ... */ } as const;
```

From src/tracks/registry.ts:
```typescript
export interface TrackInfo { id: string; name: string; controlPoints: TrackControlPoint[]; /* ... */ }
export const TRACKS: TrackInfo[];
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create HeadlessEnv controller with unit tests</name>
  <files>
    src/ai/headless-env.ts
    tests/ai/headless-env.test.ts
  </files>
  <action>
**Create `src/ai/headless-env.ts`** -- The core adapter between the game engine and AI training.

### Research Insights

**Class Design (Architecture Review + Pattern Recognition):**
- HeadlessEnv as a class is the correct pattern. It manages mutable episode state (world, stepCount, stillnessCounter) while the engine stays pure. This mirrors the existing `RaceController` pattern in the codebase.
- Track is built once in the constructor and reused across episodes (reset only recreates WorldState). `buildTrack` is expensive (~10-50ms) and should never be called per-reset.
- Type `world` as `WorldState | null` (not `WorldState`). This is required under TypeScript strict mode with `strictPropertyInitialization`. World is created in `reset()`, not the constructor.

**Wall Contact Detection -- CRITICAL (Architecture Review + Engine Explorer):**
`stepWorld` resolves wall collisions internally. After resolution, the car is pushed ~0.8 units away from the wall, so `detectWallCollision` on the resolved position returns `collided: false`. HeadlessEnv must detect wall contact independently.

**Approach:** Call `detectWallCollision` on the post-step position with a padded radius (`CAR.width / 2 + 1.0`). The padding compensates for the 0.5-0.8 unit push-out in `resolveWallCollision`. This costs one boundary scan (~1.3us) but is far cheaper than duplicating `stepWorld`'s swept collision logic.

```typescript
import { detectWallCollision } from '../engine/collision.js';
// In step(), after stepWorld:
const wallResult = detectWallCollision(
  this.world.car.position, CAR.width / 2 + 1.0, this.world.track
);
const wallContact = wallResult.collided;
```

**Compute-Once Pattern -- CRITICAL (Performance Oracle + Architecture Review):**
`distanceToTrackCenter` is the most expensive per-tick operation (~7us, 500+ spline evaluations). Both `buildObservation` and `computeReward` need its output. HeadlessEnv must compute it once per tick and share the result.

Add a `prevTrackProgress` field to cache the previous tick's result for reward computation.

**Checkpoint Count (TypeScript Review + Engine Explorer):**
`buildTrack` requires `checkpointCount` as a required parameter. The default (`DEFAULT_CHECKPOINT_COUNT = 30`) lives in `src/renderer/GameLoop.ts` -- the renderer layer, which the AI layer must NOT import. Define a local constant:

```typescript
/** Checkpoint count for AI training tracks. Matches renderer's DEFAULT_CHECKPOINT_COUNT. */
const CHECKPOINT_COUNT = 30;
```

**NaN Guard (Security Review + Spec Flow):**
`Math.max(-1, Math.min(1, NaN))` evaluates to `NaN`. If Python sends NaN in the action array, NaN propagates through the physics engine irreversibly (position, velocity, heading all become NaN). Validate with `Number.isFinite()` before clamping.

```typescript
function validateAction(raw: unknown): [number, number, number] {
  if (!Array.isArray(raw) || raw.length !== 3) {
    throw new Error('action must be a 3-element array [steer, throttle, brake]');
  }
  const [steer, throttle, brake] = raw;
  if (!Number.isFinite(steer) || !Number.isFinite(throttle) || !Number.isFinite(brake)) {
    throw new Error('action elements must be finite numbers');
  }
  return [
    Math.max(-1, Math.min(1, steer)),
    Math.max(0, Math.min(1, throttle)),
    Math.max(0, Math.min(1, brake)),
  ];
}
```

---

```typescript
export interface ResetResult {
  observation: number[];
  info: Record<string, unknown>;
}

export interface StepResult {
  observation: number[];
  reward: number;
  terminated: boolean;
  truncated: boolean;
  info: Record<string, unknown>;
}
```

Class `HeadlessEnv`:

**Fields:**
- `private readonly track: TrackState` -- built once in constructor
- `private readonly config: AiConfig` -- stored in constructor
- `private world: WorldState | null = null` -- created in reset()
- `private stepCount = 0`
- `private stillnessCounter = 0`
- `private prevTrackProgress: { distance: number; arcLength: number } = { distance: 0, arcLength: 0 }` -- cached for reward computation

**Constructor:** Takes `trackId: string` (default `'track-01'`) and `config: AiConfig` (default `DEFAULT_AI_CONFIG`). Looks up the track from `TRACKS` registry by id (throw descriptive error if not found). Calls `buildTrack(trackInfo.controlPoints, CHECKPOINT_COUNT)` to create the TrackState. Stores config. Does NOT create the world yet (that happens in reset).

**reset():** Returns `ResetResult`.
- Creates fresh WorldState via `createWorld(this.track)`
- Resets step counter to 0
- Resets stillness counter to 0
- Computes `trackProgress = distanceToTrackCenter(car.position, track)` and caches as `this.prevTrackProgress`
- Builds initial observation: `castRays(car.position, car.heading, track.innerBoundary, track.outerBoundary)` then `buildObservation(world, rays, trackProgress)`
- Returns observation + info (tick, speed, lap, checkpoint, stepCount)

**step(action: [number, number, number]):** Returns `StepResult`.
- Guard: throw `'step() called before reset()'` if `this.world` is null
- Validate and clamp action via `validateAction(action)` (checks isFinite, then clamps)
- Destructure as `[steer, throttle, brake]`
- Store `prevWorld` reference
- Call `this.world = stepWorld(this.world, { steer, throttle, brake })`
- Increment stepCount
- **Detect wall contact** via `detectWallCollision(car.position, CAR.width / 2 + 1.0, track).collided`
- **Compute `currTrackProgress`** via `distanceToTrackCenter(car.position, track)` -- ONCE per tick
- Build observation: `castRays(...)` then `buildObservation(world, rays, currTrackProgress)`
- Compute reward: `computeReward(prevWorld, this.world, wallContact, this.config.weights, { prevArcLength: this.prevTrackProgress.arcLength, currArcLength: currTrackProgress.arcLength })`
- Cache: `this.prevTrackProgress = currTrackProgress`
- Track stillness: if `car.speed < config.weights.stillnessSpeedThreshold`, increment stillness counter; else reset to 0
- Determine `terminated`: stillness counter >= `config.episode.stillnessTimeoutTicks`
- Determine `truncated`: stepCount >= `config.episode.maxSteps`
- Build info dict: all reward breakdown components (progress, speed, wall, offTrack, backward, stillness), plus tick, speed (raw), lap, checkpoint, stepCount, wallContact, stillnessCounter
- Return `{ observation, reward: rewardBreakdown.total, terminated, truncated, info }`

### Edge Cases
- **First tick after reset:** Car at rest (speed=0). Stillness penalty fires (-0.001) with near-zero progress. Net reward slightly negative. This is expected -- agent learns to start moving.
- **Step before reset:** Throws descriptive error, caught by bridge server and returned as `{ type: "error" }`.
- **NaN action values:** Caught by `validateAction`, throws before entering physics.
- **Lap boundary wrap:** Handled by `computeReward`'s modular arithmetic (Plan 01).

### Performance Considerations
- `distanceToTrackCenter` called exactly 1x per tick (result shared with observation + reward)
- `detectWallCollision` with padded radius adds ~1.3us per tick
- `castRays` brute-force against ~400 boundary segments: ~12us per tick (acceptable for Phase 4)
- Estimated total per-step cost: ~40us computation + ~100us WebSocket round-trip = ~140-180us

---

**Create `tests/ai/headless-env.test.ts`:**

Test cases:
- `reset()` returns 14-element observation array
- `reset()` resets step count (stepping after reset starts from 0)
- `step()` with neutral action (0, 0, 0) returns valid StepResult
- `step()` advances the tick counter
- `step()` with forward action (0, 1, 0) produces positive speed observation
- Episode truncates after maxSteps (use short maxSteps config for test speed)
- Episode terminates after stillness timeout (car doesn't move for N ticks, use short timeout)
- info dict contains all reward breakdown components (progress, speed, wall, offTrack, backward, stillness)
- info dict contains wallContact boolean
- Action values are clamped (steer > 1 becomes 1, throttle < 0 becomes 0)
- Action validation rejects NaN values with descriptive error
- Action validation rejects wrong-length arrays
- Multiple reset() calls work (episode restarts cleanly)
- `step()` before `reset()` throws descriptive error
- Observation values are all within [-1, 1] bounds

Use a real track (track-01 from registry) for integration-level confidence. These tests do NOT require a WebSocket server.

For truncation/termination tests, create a custom config with short `maxSteps` (e.g., 5) and short `stillnessTimeoutTicks` (e.g., 3) to avoid running thousands of ticks.

Run: `pnpm test -- tests/ai/headless-env.test.ts`

### References
- [Gymnasium terminated vs truncated](https://farama.org/Gymnasium-Terminated-Truncated-Step-API) -- Correct usage of the 5-tuple API
- [Reward design for autonomous racing (Nature, 2025)](https://www.nature.com/articles/s41598-025-27702-6) -- Reward balance research
- [Gymnasium custom env docs](https://gymnasium.farama.org/introduction/create_custom_env/) -- Box spaces, check_env
  </action>
  <verify>
    <automated>cd C:/Users/brigg/ai-learning-journey/projects/top-down-racer-02 && pnpm test -- tests/ai/headless-env.test.ts</automated>
  </verify>
  <done>
    - HeadlessEnv.reset() returns 14-value observation and info dict
    - HeadlessEnv.step() returns observation, reward, terminated, truncated, info
    - Episode truncation works at maxSteps
    - Episode termination works on stillness timeout
    - Wall contact detected via padded-radius detectWallCollision
    - distanceToTrackCenter computed once per tick (shared with observation + reward)
    - NaN action values rejected with descriptive error
    - step() before reset() throws descriptive error
    - Info dict contains per-component reward breakdown + wallContact
    - All headless-env tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Create WebSocket bridge server, entry script, and default config</name>
  <files>
    src/ai/bridge-server.ts
    src/ai/run-bridge.ts
    python/ai-config.json
  </files>
  <action>
**Step 1: Install dependencies.**

Run: `pnpm add ws && pnpm add -D @types/ws tsx`

### Research Insights

**WebSocket Server Configuration (Best Practices Research + Security Review):**
- Bind to `127.0.0.1` (localhost only) -- prevents LAN exposure. The Python client runs on the same machine.
- Set `perMessageDeflate: false` -- compression adds CPU overhead per message with zero benefit for ~200-byte localhost payloads.
- Set `skipUTF8Validation: true` -- trusted localhost client, skip unnecessary validation.
- Set `maxPayload: 65536` -- defense against oversized messages. Largest valid message is ~500 bytes.
- Enable `TCP_NODELAY` via `req.socket.setNoDelay(true)` on each connection -- disables Nagle's algorithm for lower latency ([Marc Brooker: "It's always TCP_NODELAY"](https://brooker.co.za/blog/2024/05/09/nagle.html)).
- Enable `clientTracking: true` for graceful shutdown support.

**Entry Point (Simplicity Review + TypeScript Review):**
Create a separate 3-line entry file `src/ai/run-bridge.ts` instead of main-module detection in bridge-server.ts. This keeps bridge-server.ts as a clean library module with no self-invocation logic. The entry file is trivial and unambiguous.

**Graceful Shutdown (WebSocket Research + ws docs):**
Handle SIGINT/SIGTERM to close connections cleanly. On Windows, also handle SIGBREAK. Add a forced-exit timeout as fallback.

**Input Validation (Security Review):**
- Validate action array type, length, and element finiteness before passing to HeadlessEnv
- Validate `trackId` against registry (HeadlessEnv constructor already throws on unknown track)
- Send descriptive error responses, log full errors to stderr

---

**Step 2: Create `python/ai-config.json`** -- Default reward weights file.

### Research Insights -- CORRECTED WEIGHTS (Plan 01 Research)

Plan 01's reward research found:
- `speedBonus: 0.1` would dominate progress by 37x -- agent floors throttle into walls. Set to `0.0`.
- `wallPenalty: -0.05` erases ~17 ticks of progress per contact tick -- teaches stillness. Set to `-0.002`.
- `backwardPenalty: -0.1` is redundant with negative progress delta. Set to `0.0`.
- All penalties must be smaller than typical per-tick progress (~0.003).
- **CRITICAL:** Use `offTrackPenalty` (capital T) to match the TypeScript `RewardConfig` interface. Using `offtrackPenalty` (lowercase) causes the value to be silently `undefined`.
- `stillnessSpeedThreshold` is in `weights` (not `episode`) per Plan 01's restructuring.

```json
{
  "weights": {
    "progress": 1.0,
    "speedBonus": 0.0,
    "wallPenalty": -0.002,
    "offTrackPenalty": -0.001,
    "backwardPenalty": 0.0,
    "stillnessPenalty": -0.001,
    "stillnessSpeedThreshold": 2.0
  },
  "episode": {
    "maxSteps": 3000,
    "stillnessTimeoutTicks": 180
  }
}
```

This file is loaded by the Python client and sent to the Node.js server on reset (AI-12). Values match `DEFAULT_AI_CONFIG` exactly.

---

**Step 3: Create `src/ai/bridge-server.ts`** -- WebSocket RPC server.

Import `WebSocketServer, WebSocket` from `ws`. Import `HeadlessEnv` from `./headless-env`. Import `AiConfig, DEFAULT_AI_CONFIG` from `./ai-config`.

**`startBridgeServer(port?: number)`** -- exported function. Returns `{ wss, shutdown }` for testability.

```typescript
import { WebSocketServer, WebSocket } from 'ws';

export function startBridgeServer(port = 9876) {
  const wss = new WebSocketServer({
    port,
    host: '127.0.0.1',           // Localhost only -- no LAN exposure
    perMessageDeflate: false,      // No compression for small payloads
    maxPayload: 65_536,            // 64KB limit (messages are ~200 bytes)
    skipUTF8Validation: true,      // Trusted localhost client
    clientTracking: true,          // For graceful shutdown
  });

  wss.on('connection', (ws, req) => {
    req.socket.setNoDelay(true);   // Disable Nagle's algorithm

    let env: HeadlessEnv | null = null;

    ws.on('message', (data: Buffer) => {
      let response: object;
      try {
        const msg = JSON.parse(data.toString());
        response = dispatch(msg);
      } catch (err) {
        const message = err instanceof Error ? err.message : String(err);
        console.error('[bridge] error:', message);
        response = { type: 'error', message };
      }
      ws.send(JSON.stringify(response));
    });

    function dispatch(msg: Record<string, unknown>): object {
      switch (msg.type) {
        case 'reset': { /* ... */ }
        case 'step': { /* ... */ }
        case 'close': { /* ... */ }
        default: return { type: 'error', message: `Unknown type: ${msg.type}` };
      }
    }

    ws.on('close', () => { env = null; });
    ws.on('error', (err) => {
      console.error('[bridge] connection error:', err.message);
      env = null;
    });
  });

  // ... shutdown handler, listening log ...
  return { wss, shutdown };
}
```

Protocol handlers:

**`reset`:** `{ type: "reset", trackId?: string, config?: AiConfig }`
- Create HeadlessEnv with `trackId ?? 'track-01'` and `config ?? DEFAULT_AI_CONFIG`
- Call `env.reset()`
- Send: `{ type: "reset_result", observation: number[], info: {} }`

**`step`:** `{ type: "step", action: [number, number, number] }`
- Guard: if `!env`, return error "Call reset before step"
- Call `env.step(action)` (HeadlessEnv validates the action internally)
- Send: `{ type: "step_result", observation, reward, terminated, truncated, info }`

**`close`:** `{ type: "close" }`
- Send: `{ type: "close_result" }`
- Set `env = null`

**Error handling:** Wrap each handler in try/catch. On error, send `{ type: "error", message: string }`. Log full error to stderr.

**Graceful shutdown handler:**

```typescript
function shutdown() {
  console.log('[bridge] shutting down...');
  wss.clients.forEach((client) => {
    if (client.readyState === WebSocket.OPEN) {
      client.close(1001, 'Server shutting down');
    }
  });
  wss.close(() => {
    console.log('[bridge] closed');
    process.exit(0);
  });
  setTimeout(() => process.exit(1), 5000); // Force exit after 5s
}

process.on('SIGINT', shutdown);
process.on('SIGTERM', shutdown);
```

---

**Step 4: Create `src/ai/run-bridge.ts`** -- CLI entry point.

```typescript
import { startBridgeServer } from './bridge-server.js';

const port = parseInt(process.env.BRIDGE_PORT ?? '9876', 10);
if (!Number.isFinite(port) || port < 1 || port > 65535) {
  console.error(`[bridge] Invalid port: ${process.env.BRIDGE_PORT}. Must be 1-65535.`);
  process.exit(1);
}
startBridgeServer(port);
```

This is a clean separation: bridge-server.ts is a library (importable, testable), run-bridge.ts is the CLI entry point.

---

**Step 5: Add npm script** to package.json:
```json
"bridge": "npx tsx src/ai/run-bridge.ts"
```

---

**Step 6: Verify** the server starts without errors:
- Run `pnpm bridge` and verify it logs `"[bridge] listening on ws://127.0.0.1:9876"`
- Kill the process (it's a long-running server, just verify it starts)

**Important notes:**
- The bridge server is NOT tested with vitest (it's a long-running process). Integration testing happens in Plan 03 with the Python client.
- Each WebSocket connection gets its own HeadlessEnv.
- JSON serialization is used (not binary). For 14-float vectors, JSON is fast enough and debuggable (~4-6us combined parse+stringify).
- The server always sends a response (even on error) to prevent hanging the client.

### Performance Considerations
- `perMessageDeflate: false` eliminates compression overhead per message
- `skipUTF8Validation: true` skips unnecessary validation for trusted localhost
- `setNoDelay(true)` disables Nagle's algorithm, reducing latency by up to 200ms in worst case
- `maxPayload: 65536` prevents memory spikes from oversized messages
- Estimated per-message overhead: ~4-6us JSON + ~100us WebSocket/TCP = ~106us round-trip on localhost
- Total per-step latency (including engine): ~180-300us, well under the 500us target

### Security Considerations
- Server binds to `127.0.0.1` -- not reachable from LAN
- `maxPayload` prevents memory exhaustion from large messages
- HeadlessEnv's `validateAction` prevents NaN poisoning
- Error messages include `err.message` but not stack traces
- No authentication -- acceptable for localhost-only training tool

### References
- [ws npm library](https://github.com/websockets/ws) -- WebSocket server for Node.js
- [Marc Brooker: TCP_NODELAY](https://brooker.co.za/blog/2024/05/09/nagle.html) -- Why to disable Nagle's algorithm
- [Node.js memory management](https://nodejs.org/en/learn/diagnostics/memory/understanding-and-tuning-memory) -- V8 GC tuning
  </action>
  <verify>
    <automated>cd C:/Users/brigg/ai-learning-journey/projects/top-down-racer-02 && pnpm exec tsc --noEmit && pnpm test</automated>
  </verify>
  <done>
    - bridge-server.ts compiles without TypeScript errors
    - WebSocket server binds to 127.0.0.1 with perMessageDeflate: false and TCP_NODELAY
    - python/ai-config.json contains corrected reward weights matching DEFAULT_AI_CONFIG
    - run-bridge.ts is a clean 3-line entry file
    - `pnpm bridge` starts the server and logs "listening" message
    - Graceful shutdown on SIGINT/SIGTERM
    - All existing tests still pass (no regressions)
  </done>
</task>

</tasks>

<verification>
1. `pnpm exec tsc --noEmit` -- no TypeScript errors
2. `pnpm test` -- all tests pass including headless-env tests
3. `pnpm bridge` starts and logs `[bridge] listening on ws://127.0.0.1:9876` (manual: Ctrl+C to stop)
4. python/ai-config.json exists with valid JSON, reward weights match DEFAULT_AI_CONFIG, `offTrackPenalty` uses correct casing
5. HeadlessEnv.step() computes distanceToTrackCenter exactly once per tick
6. HeadlessEnv.step() detects wall contact via padded-radius detectWallCollision
7. HeadlessEnv.step() passes wallContact to computeReward
8. HeadlessEnv rejects NaN action values with descriptive error
</verification>

<success_criteria>
- HeadlessEnv wraps engine into an episode-based RL interface (AI-01 partial)
- WebSocket bridge server accepts step/reset/close JSON messages (AI-07 server side)
- Default config file provides reward weights without code changes (AI-12)
- Episode terminates on stillness and truncates on max steps
- Wall contact detected and passed to reward function (AI-05 wall tier)
- Per-component reward breakdown in info dict (AI-13)
- distanceToTrackCenter computed once per tick (performance)
- Bridge server binds to localhost only (security)
</success_criteria>

<output>
After completion, create `.planning/phases/04-gymnasium-environment-wrapper/04-02-SUMMARY.md`
</output>
</content>
</invoke>