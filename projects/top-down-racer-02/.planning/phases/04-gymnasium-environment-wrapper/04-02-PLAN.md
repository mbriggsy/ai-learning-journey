---
phase: 04-gymnasium-environment-wrapper
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - src/ai/headless-env.ts
  - src/ai/bridge-server.ts
  - python/ai-config.json
  - tests/ai/headless-env.test.ts
autonomous: true
requirements: [AI-01, AI-07]

must_haves:
  truths:
    - "HeadlessEnv wraps createWorld/stepWorld and produces observations, rewards, and termination signals per step"
    - "WebSocket bridge server accepts step/reset/close commands and returns JSON responses"
    - "Bridge server starts on a configurable port and logs 'ready' when listening"
    - "Default reward weights are stored in a JSON config file"
    - "Episode terminates on max steps (truncated) or stillness timeout (terminated)"
  artifacts:
    - path: "src/ai/headless-env.ts"
      provides: "Headless environment controller wrapping engine + AI modules"
      exports: ["HeadlessEnv", "StepResult"]
    - path: "src/ai/bridge-server.ts"
      provides: "WebSocket RPC server for Python bridge"
      exports: ["startBridgeServer"]
    - path: "python/ai-config.json"
      provides: "Default reward weights and episode config"
    - path: "tests/ai/headless-env.test.ts"
      provides: "Headless env unit tests"
  key_links:
    - from: "src/ai/headless-env.ts"
      to: "src/engine/world.ts"
      via: "imports createWorld, stepWorld for episode management"
      pattern: "import.*createWorld.*stepWorld.*from.*engine/world"
    - from: "src/ai/headless-env.ts"
      to: "src/ai/raycaster.ts"
      via: "imports castRays for observation building"
      pattern: "import.*castRays.*from.*raycaster"
    - from: "src/ai/headless-env.ts"
      to: "src/ai/reward.ts"
      via: "imports computeReward for reward computation"
      pattern: "import.*computeReward.*from.*reward"
    - from: "src/ai/bridge-server.ts"
      to: "src/ai/headless-env.ts"
      via: "creates HeadlessEnv instance and delegates step/reset"
      pattern: "import.*HeadlessEnv.*from.*headless-env"
---

<objective>
Build the headless environment controller and WebSocket bridge server. HeadlessEnv wraps the engine's createWorld/stepWorld with AI-specific logic (ray casting, reward, termination). The bridge server exposes HeadlessEnv over WebSocket for Python to consume.

Purpose: This is the "adapter" layer that turns the game engine into an RL environment. The Python side (Plan 03) connects to this server.

Output: Two TypeScript source files in `src/ai/`, one JSON config file in `python/`, and unit tests for the headless env.
</objective>

<execution_context>
@~/.claude/commands/gsd/workflows/execute-plan.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-gymnasium-environment-wrapper/04-01-SUMMARY.md

<interfaces>
<!-- From Plan 01 outputs (src/ai/) -->

From src/ai/ai-config.ts:
```typescript
export interface RewardConfig {
  progress: number; speedBonus: number; wallPenalty: number;
  offtrackPenalty: number; backwardPenalty: number; stillnessPenalty: number;
}
export interface EpisodeConfig {
  maxSteps: number; stillnessTimeoutTicks: number; stillnessSpeedThreshold: number;
}
export interface AiConfig { weights: RewardConfig; episode: EpisodeConfig; }
export const DEFAULT_AI_CONFIG: AiConfig;
```

From src/ai/raycaster.ts:
```typescript
export function castRays(
  carPosition: Vec2, carHeading: number,
  innerBoundary: readonly Vec2[], outerBoundary: readonly Vec2[],
  numRays?: number, fovRadians?: number, maxDist?: number
): number[];
```

From src/ai/observations.ts:
```typescript
export function buildObservation(world: WorldState, rays: number[]): number[];
```

From src/ai/reward.ts:
```typescript
export interface RewardBreakdown {
  progress: number; speed: number; wall: number;
  offTrack: number; backward: number; stillness: number; total: number;
}
export function computeReward(
  prevWorld: WorldState, currWorld: WorldState, config: AiConfig
): RewardBreakdown;
```

<!-- From engine (stable, unchanged) -->

From src/engine/world.ts:
```typescript
export function createWorld(track: TrackState): WorldState;
export function stepWorld(state: WorldState, input: Input): WorldState;
```

From src/engine/track.ts:
```typescript
export function buildTrack(controlPoints: TrackControlPoint[], numCheckpoints?: number): TrackState;
```

From src/tracks/registry.ts:
```typescript
export interface TrackInfo { id: string; name: string; controlPoints: TrackControlPoint[]; /* ... */ }
export const TRACKS: TrackInfo[];
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create HeadlessEnv controller with unit tests</name>
  <files>
    src/ai/headless-env.ts
    tests/ai/headless-env.test.ts
  </files>
  <action>
**Create `src/ai/headless-env.ts`** -- The core adapter between the game engine and AI training.

```typescript
export interface StepResult {
  observation: number[];
  reward: number;
  terminated: boolean;
  truncated: boolean;
  info: Record<string, unknown>;
}
```

Class `HeadlessEnv`:

**Constructor:** Takes `trackId: string` (default `'track-01'`) and `config: AiConfig` (default `DEFAULT_AI_CONFIG`). Looks up the track from `TRACKS` registry by id, calls `buildTrack()` to create the TrackState. Stores config. Does NOT create the world yet (that happens in reset).

**reset():** Returns `{ observation: number[], info: Record<string, unknown> }`.
- Creates fresh WorldState via `createWorld(this.track)`
- Resets step counter to 0
- Resets stillness counter to 0
- Builds initial observation: `castRays(car.position, car.heading, track.innerBoundary, track.outerBoundary)` then `buildObservation(world, rays)`
- Returns observation + info (tick, speed, lap, checkpoint)

**step(action: [number, number, number]):** Returns `StepResult`.
- Destructure action as `[steer, throttle, brake]`
- Clamp values: steer to [-1, 1], throttle to [0, 1], brake to [0, 1]
- Store prevWorld reference
- Call `stepWorld(this.world, { steer, throttle, brake })`
- Increment stepCount
- Build observation (castRays + buildObservation)
- Compute reward via `computeReward(prevWorld, this.world, this.config)`
- Track stillness: if `car.speed < config.episode.stillnessSpeedThreshold`, increment stillness counter; else reset to 0
- Determine terminated: stillness counter >= `config.episode.stillnessTimeoutTicks`
- Determine truncated: stepCount >= `config.episode.maxSteps`
- Build info dict: all reward breakdown components (AI-13), plus tick, speed, lap, checkpoint, stepCount
- Return `{ observation, reward: rewardBreakdown.total, terminated, truncated, info }`

**Key design decisions:**
- HeadlessEnv is a class (not pure functions) because it manages episode state (world, stepCount, stillnessCounter)
- The engine's pure-function design is preserved: `stepWorld()` returns new state, never mutates
- Track is built once in constructor, reused across episodes (reset only recreates WorldState)
- Action clamping happens here (defense in depth -- Gymnasium Box space also clips, but we don't rely on it)

**Create `tests/ai/headless-env.test.ts`:**

Test cases:
- `reset()` returns 14-element observation array
- `reset()` resets step count (stepping after reset starts from 0)
- `step()` with neutral action (0, 0, 0) returns valid StepResult
- `step()` advances the tick counter
- `step()` with forward action (0, 1, 0) produces positive speed observation
- Episode truncates after maxSteps
- Episode terminates after stillness timeout (car doesn't move for N ticks)
- info dict contains all reward breakdown components (progress, speed, wall, offTrack, backward, stillness)
- Action values are clamped (steer > 1 becomes 1, throttle < 0 becomes 0)
- Multiple reset() calls work (episode restarts cleanly)

Use a real track (track-01 from registry) for integration-level confidence. These tests do NOT require a WebSocket server.

Run: `pnpm test -- tests/ai/headless-env.test.ts`
  </action>
  <verify>
    <automated>cd C:/Users/brigg/ai-learning-journey/projects/top-down-racer-02 && pnpm test -- tests/ai/headless-env.test.ts</automated>
  </verify>
  <done>
    - HeadlessEnv.reset() returns 14-value observation and info dict
    - HeadlessEnv.step() returns observation, reward, terminated, truncated, info
    - Episode truncation works at maxSteps
    - Episode termination works on stillness timeout
    - Info dict contains per-component reward breakdown
    - All headless-env tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Create WebSocket bridge server and default config</name>
  <files>
    src/ai/bridge-server.ts
    python/ai-config.json
  </files>
  <action>
**Step 1: Install `ws` dependency.**

Run: `pnpm add ws && pnpm add -D @types/ws`

**Step 2: Create `python/ai-config.json`** -- Default reward weights file.

```json
{
  "weights": {
    "progress": 1.0,
    "speedBonus": 0.1,
    "wallPenalty": -0.05,
    "offtrackPenalty": -0.02,
    "backwardPenalty": -0.1,
    "stillnessPenalty": -0.1
  },
  "episode": {
    "maxSteps": 3000,
    "stillnessTimeoutTicks": 180,
    "stillnessSpeedThreshold": 2.0
  }
}
```

This file is loaded by the Python client and sent to the Node.js server on reset (AI-12).

**Step 3: Create `src/ai/bridge-server.ts`** -- WebSocket RPC server.

Import `WebSocketServer` from `ws`. Import `HeadlessEnv` from `./headless-env`. Import `AiConfig, DEFAULT_AI_CONFIG` from `./ai-config`.

**`startBridgeServer(port?: number)`** -- exported function.

- Default port: 9876
- Create `WebSocketServer` on the port
- Log `"[bridge] listening on ws://localhost:{port}"` when ready
- On connection, create a `HeadlessEnv` instance (one per connection)
- On message (JSON string), parse and dispatch:

Protocol handlers:

**`reset`:** `{ type: "reset", trackId?: string, config?: AiConfig }`
- If `trackId` or `config` provided, create new HeadlessEnv with those params
- Otherwise reuse existing env with existing config
- Call `env.reset()`
- Send: `{ type: "reset_result", observation: number[], info: {} }`

**`step`:** `{ type: "step", action: [number, number, number] }`
- Call `env.step(action)`
- Send: `{ type: "step_result", observation, reward, terminated, truncated, info }`

**`close`:** `{ type: "close" }`
- Send: `{ type: "close_result" }`
- Close the connection

**Error handling:** Wrap each handler in try/catch. On error, send `{ type: "error", message: string }`. Log errors to stderr.

**CLI entry point:** Add a section at the bottom:

```typescript
// Run as standalone server when executed directly
if (process.argv[1] && import.meta.url.endsWith(process.argv[1].replace(/\\/g, '/'))) {
  const port = parseInt(process.env.BRIDGE_PORT ?? '9876', 10);
  startBridgeServer(port);
}
```

Actually, since this is ESM + Vite project, use a simpler approach: create a separate entry script or use `tsx` to run it. The bridge-server needs to run under Node.js (not browser). Add a script to package.json:

```json
"bridge": "npx tsx src/ai/bridge-server.ts"
```

Or better, add conditional main-module detection for ESM:

```typescript
// At bottom of bridge-server.ts:
const isMain = process.argv[1]?.replace(/\\/g, '/').includes('bridge-server');
if (isMain) {
  const port = parseInt(process.env.BRIDGE_PORT ?? '9876', 10);
  startBridgeServer(port);
}
```

**Step 4: Add npm script** to package.json:
```json
"bridge": "npx tsx src/ai/bridge-server.ts"
```

This requires `tsx` as a dev dependency: `pnpm add -D tsx`

**Step 5: Verify** the server starts without errors:
- Run `pnpm bridge` and verify it logs the "listening" message
- Kill the process (it's a long-running server, just verify it starts)

**Important notes:**
- The bridge server is NOT tested with vitest (it's a long-running process). Integration testing happens in Plan 03 with the Python client.
- Each WebSocket connection gets its own HeadlessEnv (supports future parallel training).
- JSON serialization is used (not binary). For 14-float vectors, JSON is fast enough and debuggable.
- The server must handle the case where `step()` is called before `reset()` -- return an error message.
  </action>
  <verify>
    <automated>cd C:/Users/brigg/ai-learning-journey/projects/top-down-racer-02 && pnpm exec tsc --noEmit && pnpm test</automated>
  </verify>
  <done>
    - bridge-server.ts compiles without TypeScript errors
    - WebSocket server accepts connections and dispatches reset/step/close messages
    - python/ai-config.json contains default reward weights matching DEFAULT_AI_CONFIG
    - `pnpm bridge` starts the server and logs "listening" message
    - All existing tests still pass (no regressions)
  </done>
</task>

</tasks>

<verification>
1. `pnpm exec tsc --noEmit` -- no TypeScript errors
2. `pnpm test` -- all tests pass including headless-env tests
3. `pnpm bridge` starts and logs ready message (manual: Ctrl+C to stop)
4. python/ai-config.json exists with valid JSON matching the AiConfig schema
</verification>

<success_criteria>
- HeadlessEnv wraps engine into an episode-based RL interface (AI-01 partial)
- WebSocket bridge server accepts step/reset/close JSON messages (AI-07 server side)
- Default config file provides reward weights without code changes (AI-12)
- Episode terminates on stillness and truncates on max steps
</success_criteria>

<output>
After completion, create `.planning/phases/04-gymnasium-environment-wrapper/04-02-SUMMARY.md`
</output>
